{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **모델 훈련 연습 문제**\n",
        "___\n",
        "- 출처 : 핸즈온 머신러닝 Ch04 연습문제 1, 5, 9, 10\n",
        "- 개념 문제의 경우 텍스트 셀을 추가하여 정답을 적어주세요."
      ],
      "metadata": {
        "id": "zCu72vDHGMHo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. 수백만 개의 특성을 가진 훈련 세트에서는 어떤 선형 회귀 알고리즘을 사용할 수 있을까요?**\n",
        "___\n"
      ],
      "metadata": {
        "id": "j3g-_Dq9GiuT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "확률적 경사 하강법, 미니배치 경사 하강법"
      ],
      "metadata": {
        "id": "AqmkV6mvSJaE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. 배치 경사 하강법을 사용하고 에포크마다 검증 오차를 그래프로 나타내봤습니다. 검증 오차가 일정하게 상승되고 있다면 어떤 일이 일어나고 있는 걸까요? 이 문제를 어떻게 해결할 수 있나요?**\n",
        "___"
      ],
      "metadata": {
        "id": "-pDjW5XcHPOt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습률이 너무 높기 때문이다. 학습률을 낮춘다."
      ],
      "metadata": {
        "id": "qX5hV_4wSxNG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3. 릿지 회귀를 사용했을 때 훈련 오차가 검증 오차가 거의 비슷하고 둘 다 높았습니다. 이 모델에는 높은 편향이 문제인가요, 아니면 높은 분산이 문제인가요? 규제 하이퍼파라미터 $\\alpha$를 증가시켜야 할까요 아니면 줄여야 할까요?**\n",
        "___"
      ],
      "metadata": {
        "id": "nM7JbsLoy7b7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "높은 편향이 문제다. 하이퍼파라미터를 줄여야 한다."
      ],
      "metadata": {
        "id": "h7pYIrOaS8vo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4. 다음과 같이 사용해야 하는 이유는?**\n",
        "___\n",
        "- 평범한 선형 회귀(즉, 아무런 규제가 없는 모델) 대신 릿지 회귀\n",
        "- 릿지 회귀 대신 라쏘 회귀\n",
        "- 라쏘 회귀 대신 엘라스틱넷"
      ],
      "metadata": {
        "id": "C8tARu-ZzOGx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 평범한 선형회귀보다는 규제가 있는 모델의 성능이 일반적으로 좋기 때문이다.\n",
        "\n",
        "* 특성이 몇 개뿐일 것 같을때.\n",
        "\n",
        "* 특성끼리 강하게 연관된 경우에 적합."
      ],
      "metadata": {
        "id": "RWHV3lCGTLVV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **추가) 조기 종료를 사용한 배치 경사 하강법으로 iris 데이터를 활용해 소프트맥스 회귀를 구현해보세요(사이킷런은 사용하지 마세요)**\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "QIZpOEYJVIAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "\n",
        "X = iris[\"data\"][:, (2,3)]\n",
        "y = iris['target']"
      ],
      "metadata": {
        "id": "8pXDQ_fU8Nz0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 원-핫 인코딩\n",
        "num_classes = len(np.unique(y))\n",
        "y_onehot = np.eye(num_classes)[y]\n",
        "\n",
        "X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
        "\n",
        "np.random.seed(42)\n",
        "indices = np.random.permutation(len(X))\n",
        "train_size = int(0.8 * len(X))\n",
        "train_idx, val_idx = indices[:train_size], indices[train_size:]\n",
        "\n",
        "X_train, y_train = X[train_idx], y_onehot[train_idx]\n",
        "X_val, y_val = X[val_idx], y_onehot[val_idx]\n",
        "\n",
        "def softmax(z):\n",
        "    exp_z = np.exp(z - np.max(z, axis=1, keepdims=True))\n",
        "    return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
        "\n",
        "def compute_loss(y_true, y_pred):\n",
        "    m = y_true.shape[0]\n",
        "    return -np.sum(y_true * np.log(y_pred + 1e-9)) / m\n",
        "\n",
        "n_features = X.shape[1]\n",
        "W = np.zeros((n_features, num_classes))\n",
        "b = np.zeros((1, num_classes))\n",
        "\n",
        "learning_rate = 0.1\n",
        "max_epochs = 5000\n",
        "patience = 50\n",
        "best_val_loss = np.inf\n",
        "patience_counter = 0\n",
        "\n",
        "train_losses, val_losses = [], []\n",
        "\n",
        "# 배치 경사 하강법 학습\n",
        "for epoch in range(max_epochs):\n",
        "    logits = X_train.dot(W) + b\n",
        "    y_pred = softmax(logits)\n",
        "    train_loss = compute_loss(y_train, y_pred)\n",
        "    grad_W = (1 / X_train.shape[0]) * X_train.T.dot(y_pred - y_train)\n",
        "    grad_b = (1 / X_train.shape[0]) * np.sum(y_pred - y_train, axis=0, keepdims=True)\n",
        "    W -= learning_rate * grad_W\n",
        "    b -= learning_rate * grad_b\n",
        "\n",
        "    val_pred = softmax(X_val.dot(W) + b)\n",
        "    val_loss = compute_loss(y_val, val_pred)\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "    # 조기 종료\n",
        "    if val_loss < best_val_loss - 1e-5:\n",
        "        best_val_loss = val_loss\n",
        "        patience_counter = 0\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Early stopping at epoch {epoch}\")\n",
        "            break"
      ],
      "metadata": {
        "id": "18tBw55_UC1y"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 정확도\n",
        "y_train_pred = np.argmax(softmax(X_train.dot(W)+b), axis=1)\n",
        "y_val_pred = np.argmax(softmax(X_val.dot(W)+b), axis=1)\n",
        "train_acc = np.mean(y_train_pred == np.argmax(y_train, axis=1))\n",
        "val_acc = np.mean(y_val_pred == np.argmax(y_val, axis=1))\n",
        "print(train_acc, val_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUSymHwtWakC",
        "outputId": "5f29f6ea-6f91-49ab-e148-847005d8cad9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9583333333333334 0.9666666666666667\n"
          ]
        }
      ]
    }
  ]
}
